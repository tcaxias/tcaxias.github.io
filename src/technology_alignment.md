# Technology Alignment

Instead of a proper tech radar I wrote this to state my bias openly.

Take [D&D alignments](https://en.wikipedia.org/wiki/Alignment_(Dungeons_%26_Dragons)#Alignments)
where the _lawful/chaotic_ axis would evaluate the
restrictions while developing and the _good/bad_ axis would evaluate the amount
of pain you get while operating that code.
These are orthogonal, any language, framework, system design or technique
will evaluate to specific value on both axes regarding the task at hand.

Orthogonal to these two axes I'll add a _logic_ axis, in D&D would be
whether someone is breaking role-play, which translates to cost-benefit
or the _I_ in [ROI](https://en.wikipedia.org/wiki/Return_on_investment).
Overengineering is measured here, since we're talking about product engineering
and not plain engineering.
As corollary there are two sentences, the practical [chaotic
stupid](https://tvtropes.org/pmwiki/pmwiki.php/Main/ChaoticStupid) is not an
alignment and the philosophical there is [nothing so
useless](https://www.goodreads.com/quotes/348436-there-is-nothing-so-useless-as-doing-efficiently-that-which)
as doing efficiently that which should not be done at all.

I am biased towards _lawful good_, I prefer the lawful and the good ends of
the axes.
Furthermore, I consider the _logic_ axis to be prohibitive below a
certain threshold.
If something is lower than a reasonable value on the logic axis then a
major issue is happening.

The rationale here is, when you're being paid to build something and you
imagine, dream of or make up requirements not originally there, then
you're costing the company both time to market and money, the worst part
is that these costs are hidden.
Never, ever, do this.
Ever.
If you believe some requirements should be there then talk to your peers
and double check that's true.
Don't [disagree and commit](https://en.wikipedia.org/wiki/Disagree_and_commit)
on this, just raise awareness and, ultimately, leave.
Everyone in a group must be moving to the same target.
Always.
Maturity turns out to have a large slice of "can you measure the I in ROI",
if it's not worth doing, don't do it, there is hardly anything as bad as
failing on this analysis.
